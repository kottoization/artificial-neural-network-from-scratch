# -*- coding: utf-8 -*-
"""Kopia notatnika projekt (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XhMYEZ2hrOhReviRydKlZLxNhKkgN20U

Importujemy potrzebne biblioteki
"""

import pandas as pd
from sklearn import preprocessing
from scipy import stats
from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf
from sklearn.model_selection import train_test_split
import random
from matplotlib import pyplot as plt

"""Wczytywanie danych i szybki przegląd"""

df = pd.read_csv('stroke-data.csv')
df.info()

df.head()

df.shape

pd.DataFrame(pd.unique(df.ever_married), columns=['ever_married'])

pd.DataFrame(pd.unique(df.gender), columns=['gender'])

pd.DataFrame(pd.unique(df.work_type), columns=['work_type'])

pd.DataFrame(pd.unique(df.smoking_status), columns=['smoking_status'])

pd.DataFrame(pd.unique(df.Residence_type), columns=['Residence_type'])

"""Usuwamy niepotrzebną kolumnę, ponieważ 'id' nie ma żadnego wpływu na występowanie udaru."""

df = df.drop(columns='id')

"""Sprawdzamy czy występują jakieś braki w danych"""

df.isnull().sum()

"""Usuwamy wiersze, które zawierają braki w danych"""

df = df.dropna(axis=0)

"""One-hot encoding kategorycznych zmiennych"""

temp = pd.get_dummies(df.loc[:,['gender', 'work_type', 'Residence_type', 'smoking_status']])

"""Usuwamy te kolumny, dla których zastosowaliśmy one-hot-encoding"""

df.drop(columns=['gender', 'work_type', 'Residence_type', 'smoking_status'], inplace=True)

"""Dołączamy do naszej ramki ramkę danych z zakodowanymi zmiennymi"""

df = pd.concat([df, temp], axis=1)

"""Zamieniamy zmienną 'ever_married' na wartości 0-1"""

df.ever_married = df.ever_married.map(dict(Yes=1, No=0))

df.head()

list(df.columns)

"""Normalizacja zmiennych ilościowych"""

cols_to_norm = ['age', 'avg_glucose_level', 'bmi']
df2 = df.copy()
df[cols_to_norm] = df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))

"""Losowo ustawiamy wiersze w ramce danych"""

df = df.sample(frac = 1)

"""Dzielimy dane na treningowe i testowe"""

x = df.drop(columns='stroke')
y = df.stroke
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)

"""Tworzymy model deklaracją sieci - sekwencyjną, pozwala nam to na tworzenie modelu warstwa po warstwie. Jest odpowiedni dla zwykłego stosu warstw, w którym każda warstwa ma dokładnie jeden tensor wejściowy i jeden tensor wyjściowy. W tym przypadku do modelu dodajemy 5 warstw, pierwsza z nich to warstwa wejściowa, kolejne 3 to warstwy ukryte, a piąta z nich to warstwa wyjściowa, gdzie funkcją aktywacji jest sigmoid, ponieważ jest najlepszy do problemów binarnych."""

model = Sequential()
#input_shape=x_train.shape
model.add(Dense(20, input_dim=20, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])

#model.evaluate(x_test, y_test)
history = model.fit(x_train, y_train,validation_split=0.2, batch_size=32,  epochs=100, verbose = 0 )

"""Sprawdzenie wartości history key, przy ponownym uruchomieniu kodu wartość się nadpisuje, a więc może być potrzeba zniany wartości recall na np recall_1/recall_2 itd"""

history.history.keys()

plt.plot(history.history['recall'],label='recall')
plt.plot(history.history['val_recall'],label='val_recall')
plt.legend()
plt.show()

plt.plot(history.history['precision'],label='recall')
plt.plot(history.history['val_precision'],label='val_recall')
plt.legend()
plt.show()

from sklearn.metrics import accuracy_score
y_pred=model.predict(x_test)
y_pred=(y_pred>0.5).astype(int)

from sklearn.metrics import  confusion_matrix
print(confusion_matrix(y_pred,y_test))
print("Classification on Depp Learning Accuracy score",accuracy_score(y_test,y_pred))
Deep_Learning_Score=accuracy_score(y_test,y_pred)

plt.plot(history.history['accuracy'],label='train')
plt.plot(history.history['val_accuracy'],label='val_accuracy')

plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend()
plt.show()

"""Poniżej zajmiemy się stworzeniem modelu na zbilansowanych danych, czyli zmienna stroke będzie 50/50 w wartościach 0/1.

Jak widać w naszym zbiorze danych, jest znaczna przewaga tego, że ktoś nie będzie miał udaru.
"""

df["stroke"].value_counts()

"""Tworzymy nową ramkę danych gdzie będzie 50/50 wierszy z wartościami 'stroke' 0 oraz 1. Ustawiamy, żeby wiersze z tymi samymi wartościami 'stroke' występowały w ramce losowo."""

temp1 = df[df.stroke == 1].sample(209)
temp2 = df[df.stroke == 0].sample(209)
df418 = pd.concat([temp1,temp2],axis=0)
df418 = df418.sample(frac=1)
df418.info()

"""Podział danych"""

x418 = df418.drop(columns='stroke')
y418 = df418.stroke
x418_train, x418_test, y418_train, y418_test = train_test_split(x418, y418, test_size=0.2)

"""Tworzymy model"""

model418 = Sequential()
model418.add(Dense(20, input_dim=20, activation='relu'))
model418.add(Dense(16, activation='relu'))
model418.add(Dense(16, activation='relu'))
model418.add(Dense(8, activation='relu'))
model418.add(Dense(1, activation='sigmoid'))

"""Kompilujemy model"""

model418.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])

"""Fit model to test data"""

history418 = model418.fit(x418_train, y418_train, validation_data=(x418_test, y418_test), epochs=40, verbose=0)

"""Evaluate model and see the accuracy"""

train_acc = model418.evaluate(x418_train, y418_train, verbose=0)
test_acc = model418.evaluate(x418_test, y418_test, verbose=0)
print('Train: %.3f, Test: %.3f' % (train_acc[1], test_acc[1]))

history418.history.keys()

# ponownie w zależności od otrzymanych wartości może być konieczność zmiany zaciąganej zmiennej przy rysowaniu wykresów

plt.subplot(211)
plt.title('Loss')
plt.plot(history418.history['loss'], label='train')
plt.plot(history418.history['val_loss'], label='test')
plt.legend()

plt.subplot(212)
plt.title('Accuracy')
plt.plot(history418.history['accuracy'], label='train')
plt.plot(history418.history['val_accuracy'], label='test')
plt.legend()
plt.show()

plt.plot(history418.history['recall_1'])
plt.plot(history418.history['val_recall_1'])

plt.plot(history418.history['precision_1'])
plt.plot(history418.history['val_precision_1'])